{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerai Crypto Competitie Voorspellingsmodel met H2O Sparkling Water\n",
    "\n",
    "Dit notebook implementeert een voorspellingsmodel voor de Numerai/Numerai Crypto competitie met behulp van H2O Sparkling Water, wat H2O integreert met Apache Spark voor gedistribueerde verwerking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installatie van benodigde packages\n",
    "\n",
    "Eerst moeten we Java, Spark en H2O Sparkling Water installeren. Dit kan enige tijd duren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# Create directory for Numerai data and models\n",
    "!mkdir -p \"/content/drive/My Drive/Numerai_Crypto\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if GPU is available\n",
    "!nvidia-smi"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Installeer Java (vereist voor H2O en Spark)\n",
    "!apt-get update -qq\n",
    "!apt-get install -y default-jre > /dev/null\n",
    "!java -version\n",
    "\n",
    "# Installeer Spark en PySpark\n",
    "!pip install -q pyspark==3.1.2\n",
    "\n",
    "# Installeer H2O Sparkling Water\n",
    "!pip install -q h2o-pysparkling-3.1\n",
    "\n",
    "# Installeer andere benodigde packages\n",
    "!pip install -q numerapi pandas h2o cloudpickle==2.2.1 pyarrow scikit-learn scipy==1.10.1 matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importeren van benodigde libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from numerapi import NumerAPI\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# H2O Sparkling Water imports\n",
    "from pysparkling import H2OContext\n",
    "from pysparkling.ml import H2OXGBoostEstimator\n",
    "\n",
    "import h2o\n",
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialiseren van Spark en H2O Sparkling Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialiseer Spark sessie\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NumeraiSparklingWater\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Initialiseer H2O Sparkling Water context\n",
    "h2o_context = H2OContext.getOrCreate()\n",
    "\n",
    "# Print Spark en H2O versie informatie\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"H2O cluster version: {h2o_context.getH2OVersion()}\")\n",
    "print(f\"Sparkling Water version: {h2o_context.getSparklingWaterVersion()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialiseren van de Numerai API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialiseer de Numerai API client\n",
    "# Voor het indienen van voorspellingen zijn API keys nodig\n",
    "# napi = NumerAPI(public_id=\"UW_PUBLIC_ID\", secret_key=\"UW_SECRET_KEY\")\n",
    "napi = NumerAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data downloaden en laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Gebruik een van de nieuwste dataversies\n",
    "DATA_VERSION = \"v5.0\"\n",
    "\n",
    "# Maak een data directory\n",
    "!mkdir -p {DATA_VERSION}\n",
    "\n",
    "# Download data\n",
    "print(\"Downloading training data...\")\n",
    "napi.download_dataset(f\"{DATA_VERSION}/train.parquet\")\n",
    "napi.download_dataset(f\"{DATA_VERSION}/features.json\")\n",
    "\n",
    "# Laad feature metadata\n",
    "feature_metadata = json.load(open(f\"{DATA_VERSION}/features.json\"))\n",
    "print(\"Available feature sets:\", list(feature_metadata[\"feature_sets\"].keys()))\n",
    "features = feature_metadata[\"feature_sets\"][\"small\"]  # gebruik \"small\" voor sneller testen, \"medium\" of \"all\" voor betere prestaties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data laden met PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Laad trainingsdata met Spark\n",
    "print(\"Loading training data with Spark...\")\n",
    "train_spark = spark.read.parquet(f\"{DATA_VERSION}/train.parquet\")\n",
    "\n",
    "# Selecteer alleen de benodigde kolommen\n",
    "columns_to_select = [\"era\"] + features + [\"target\"]\n",
    "train_spark = train_spark.select(*columns_to_select)\n",
    "\n",
    "# Downsampling voor snelheid (optioneel)\n",
    "print(\"Preparing data for training...\")\n",
    "# Haal unieke era's op en sample 25% (elke 4e era)\n",
    "unique_eras = [row.era for row in train_spark.select(\"era\").distinct().collect()]\n",
    "sampled_eras = unique_eras[::4]\n",
    "train_spark = train_spark.filter(col(\"era\").isin(sampled_eras))\n",
    "\n",
    "# Bekijk de data\n",
    "print(f\"Training data count: {train_spark.count()}\")\n",
    "print(f\"Number of features: {len(features)}\")\n",
    "print(f\"Number of eras: {len(sampled_eras)}\")\n",
    "\n",
    "# Toon schema\n",
    "train_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data voorbereiden met PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Bereid data voor met Spark ML Pipeline\n",
    "print(\"Preparing feature vector with Spark...\")\n",
    "\n",
    "# Maak een feature vector van alle features\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "train_spark = assembler.transform(train_spark)\n",
    "\n",
    "# Toon een voorbeeld van de getransformeerde data\n",
    "train_spark.select(\"era\", \"features\", \"target\").show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converteren van Spark DataFrame naar H2O Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Converteer Spark DataFrame naar H2O Frame\n",
    "print(\"Converting Spark DataFrame to H2O Frame...\")\n",
    "train_h2o = h2o_context.asH2OFrame(train_spark)\n",
    "\n",
    "# Bekijk H2O Frame info\n",
    "train_h2o.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trainen met H2O XGBoost via Sparkling Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train model met H2O XGBoost via Sparkling Water\n",
    "print(\"Training H2O XGBoost model via Sparkling Water...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Configureer XGBoost model\n",
    "from h2o.estimators.xgboost import H2OXGBoostEstimator\n",
    "\n",
    "xgb_model = H2OXGBoostEstimator(\n",
    "    ntrees=2000,\n",
    "    max_depth=5,\n",
    "    learn_rate=0.01,\n",
    "    sample_rate=0.8,\n",
    "    col_sample_rate=0.8,\n",
    "    tree_method=\"auto\",  # auto selecteert GPU indien beschikbaar\n",
    "    booster=\"gbtree\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train het model\n",
    "xgb_model.train(x=features, y=\"target\", training_frame=train_h2o)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Toon model informatie\n",
    "print(xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance visualiseren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature importance visualiseren\n",
    "feature_importance = xgb_model.varimp(use_pandas=True)\n",
    "if feature_importance is not None:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(range(len(feature_importance[:20])), feature_importance[:20]['relative_importance'])\n",
    "    plt.yticks(range(len(feature_importance[:20])), feature_importance[:20]['variable'])\n",
    "    plt.title('H2O XGBoost Feature Importance (top 20)')\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model opslaan als MOJO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sla het model op als MOJO (Model Object, Optimized)\n",
    "mojo_path = xgb_model.download_mojo(path=\"./\", get_genmodel_jar=True)\n",
    "print(f\"Model saved as MOJO: {mojo_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validatiedata laden en voorbereiden met PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download validatiedata voor testen\n",
    "print(\"Downloading validation data for testing...\")\n",
    "napi.download_dataset(f\"{DATA_VERSION}/validation.parquet\")\n",
    "\n",
    "# Laad validatiedata met Spark\n",
    "print(\"Loading validation data with Spark...\")\n",
    "validation_spark = spark.read.parquet(f\"{DATA_VERSION}/validation.parquet\")\n",
    "\n",
    "# Selecteer alleen de benodigde kolommen\n",
    "columns_to_select = [\"era\", \"data_type\"] + features\n",
    "validation_spark = validation_spark.select(*columns_to_select)\n",
    "\n",
    "# Filter alleen validatie data\n",
    "validation_spark = validation_spark.filter(col(\"data_type\") == \"validation\")\n",
    "\n",
    "# Neem een kleine subset voor geheugeneffici\u00ebntie\n",
    "validation_spark = validation_spark.limit(1000)\n",
    "\n",
    "# Maak een feature vector van alle features\n",
    "validation_spark = assembler.transform(validation_spark)\n",
    "\n",
    "# Converteer Spark DataFrame naar H2O Frame\n",
    "validation_h2o = h2o_context.asH2OFrame(validation_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voorspellingen maken met het model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Maak voorspellingen met het model\n",
    "print(\"Making predictions...\")\n",
    "predictions_h2o = xgb_model.predict(validation_h2o)\n",
    "\n",
    "# Converteer H2O Frame terug naar Spark DataFrame\n",
    "predictions_spark = h2o_context.asSparkFrame(predictions_h2o)\n",
    "\n",
    "# Toon voorspellingen\n",
    "print(\"Sample predictions:\")\n",
    "predictions_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voorspellingsfunctie defini\u00ebren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Definieer voorspellingsfunctie die werkt met H2O model\n",
    "def predict(\n",
    "    live_features: pd.DataFrame,\n",
    "    live_benchmark_models: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    # Converteer pandas DataFrame naar Spark DataFrame\n",
    "    live_features_spark = spark.createDataFrame(live_features[features])\n",
    "    \n",
    "    # Maak een feature vector van alle features\n",
    "    live_features_spark = assembler.transform(live_features_spark)\n",
    "    \n",
    "    # Converteer Spark DataFrame naar H2O Frame\n",
    "    live_features_h2o = h2o_context.asH2OFrame(live_features_spark)\n",
    "    \n",
    "    # Maak voorspellingen met het H2O model\n",
    "    preds = xgb_model.predict(live_features_h2o)\n",
    "    \n",
    "    # Converteer H2O voorspellingen terug naar pandas\n",
    "    predictions = h2o.as_list(preds)[\"predict\"].values\n",
    "    \n",
    "    # Maak submission DataFrame\n",
    "    submission = pd.Series(predictions, index=live_features.index)\n",
    "    return submission.to_frame(\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voorspellingsfunctie testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Converteer Spark DataFrame terug naar pandas voor testen\n",
    "validation_pd = validation_spark.toPandas()\n",
    "\n",
    "# Test voorspellingsfunctie\n",
    "print(\"Testing prediction function...\")\n",
    "# Maak een lege DataFrame voor benchmark_models (niet gebruikt in onze voorspellingsfunctie)\n",
    "empty_benchmark = pd.DataFrame(index=validation_pd.index)\n",
    "predictions = predict(validation_pd, empty_benchmark)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "print(predictions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voorspellingsfunctie opslaan met cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Pickle voorspellingsfunctie\n",
    "print(\"Saving prediction function with cloudpickle...\")\n",
    "p = cloudpickle.dumps(predict)\n",
    "with open(\"numerai_sparkling_water_model.pkl\", \"wb\") as f:\n",
    "    f.write(p)\n",
    "\n",
    "print(\"Prediction function saved as 'numerai_sparkling_water_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle specifieke functies voor het opslaan van resultaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Opslaan van resultaten in Kaggle output\n",
    "# Dit maakt het mogelijk om de resultaten te downloaden of als dataset te gebruiken\n",
    "try:\n",
    "    # Maak een output directory\n",
    "    !mkdir -p /kaggle/working/output\n",
    "    \n",
    "    # Kopieer de belangrijke bestanden\n",
    "    !cp numerai_sparkling_water_model.pkl /kaggle/working/output/\n",
    "    !cp {mojo_path} /kaggle/working/output/\n",
    "    \n",
    "    print(\"Model bestanden opgeslagen in Kaggle output directory\")\n",
    "except Exception as e:\n",
    "    print(f\"Fout bij opslaan in Kaggle output: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voordelen van Sparkling Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Hier zou je een vergelijking kunnen maken tussen standaard H2O en Sparkling Water\n",
    "print(\"Sparkling Water Voordelen:\")\n",
    "print(\"1. Gedistribueerde verwerking met Spark voor grote datasets\")\n",
    "print(\"2. Combinatie van Spark's data processing met H2O's machine learning algoritmes\")\n",
    "print(\"3. Betere schaalbaarheid voor complexe modellen en grote datasets\")\n",
    "print(\"4. Mogelijkheid om Spark ML Pipeline te integreren met H2O modellen\")\n",
    "print(f\"5. Onze training duurde {training_time:.2f} seconden met Sparkling Water\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afsluiten van Spark en H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sluit H2O cluster af\n",
    "h2o.cluster().shutdown()\n",
    "\n",
    "# Sluit Spark sessie af\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}