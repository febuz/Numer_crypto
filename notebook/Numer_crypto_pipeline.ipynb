{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerai Crypto Prediction Pipeline\n",
    "\n",
    "This notebook implements the complete pipeline for generating cryptocurrency predictions for the Numerai Crypto competition. The pipeline includes data retrieval, feature engineering, model training, and submission generation.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Data Retrieval**: Download data from Numerai and Yiedl APIs\n",
    "2. **Data Processing**: Clean and prepare data for feature generation\n",
    "3. **Feature Engineering**: Generate predictive features using GPU acceleration\n",
    "4. **Model Training**: Train multiple GPU-accelerated models (LightGBM, XGBoost, etc.)\n",
    "5. **Ensemble Creation**: Combine model predictions for optimal performance\n",
    "6. **Submission Generation**: Format predictions for Numerai submission\n",
    "\n",
    "## Hardware Requirements\n",
    "\n",
    "For optimal performance:\n",
    "- RAM: 600GB+ (minimum 16GB for simple pipeline)\n",
    "- GPU: 3x GPUs with CUDA support (minimum 1 for simple pipeline)\n",
    "- CPU: 96 threads (minimum 8 for simple pipeline)\n",
    "- Storage: 500GB+ free space\n",
    "\n",
    "This notebook has two execution modes:\n",
    "- **Quick Mode**: 15-30 minutes, minimal resource usage\n",
    "- **Optimal Mode**: 4-8 hours, high resource usage for best predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, we'll set up our environment and import necessary dependencies. We'll also set some configuration parameters that will control the pipeline's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add repository root to path\n",
    "# If running from the notebook directory, move up one level to find the root\n",
    "repo_root = Path.cwd().parent if Path.cwd().name == 'notebook' else Path.cwd()\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "# Import project configuration\n",
    "from config.settings import (\n",
    "    EXTERNAL_DATA_DIR, DATA_DIR, MODELS_DIR, SUBMISSION_DIR, \n",
    "    RAW_DATA_DIR, PROCESSED_DATA_DIR, FEATURES_DIR, CHECKPOINTS_DIR\n",
    ")\n",
    "from config.tournament_config import TOURNAMENT_NAME, get_tournament_endpoint\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "os.makedirs(EXTERNAL_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "\n",
    "# Print environment information\n",
    "logger.info(f\"Python version: {sys.version}\")\n",
    "logger.info(f\"Numerai tournament: {TOURNAMENT_NAME}\")\n",
    "logger.info(f\"Data directory: {DATA_DIR}\")\n",
    "logger.info(f\"Models directory: {MODELS_DIR}\")\n",
    "logger.info(f\"Submission directory: {SUBMISSION_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Configuration Parameters\n",
    "# These parameters control the pipeline's behavior\n",
    "\n",
    "# Execution mode: 'quick' or 'optimal'\n",
    "EXECUTION_MODE = 'quick'  # Change to 'optimal' for best performance\n",
    "\n",
    "# GPU usage\n",
    "USE_GPU = True  # Set to False to use CPU only\n",
    "\n",
    "# Data settings\n",
    "SKIP_DOWNLOAD = False  # Set to True to skip data download and use existing data\n",
    "SKIP_YIEDL = False  # Set to True to use only Numerai data (no Yiedl)\n",
    "INCLUDE_HISTORICAL = True  # Set to False to use only the latest data\n",
    "\n",
    "# Feature generation settings\n",
    "if EXECUTION_MODE == 'quick':\n",
    "    MAX_ITERATIONS = 1\n",
    "    FEATURES_PER_ITERATION = 1000\n",
    "else:  # optimal mode\n",
    "    MAX_ITERATIONS = 3\n",
    "    FEATURES_PER_ITERATION = 7500\n",
    "\n",
    "# Model training settings\n",
    "GPU_MEMORY_LIMIT = 8  # Set based on your GPU memory (in GB)\n",
    "USE_AZURE_SYNAPSE = True  # Use Azure Synapse LightGBM for faster training\n",
    "\n",
    "# Display configuration\n",
    "logger.info(f\"Execution mode: {EXECUTION_MODE}\")\n",
    "logger.info(f\"GPU usage: {USE_GPU}\")\n",
    "logger.info(f\"Maximum iterations: {MAX_ITERATIONS}\")\n",
    "logger.info(f\"Features per iteration: {FEATURES_PER_ITERATION}\")\n",
    "logger.info(f\"GPU memory limit: {GPU_MEMORY_LIMIT}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU Detection and Optimization\n",
    "\n",
    "Now we'll check for available GPUs and configure them for optimal performance. This is critical for the high-performance pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GPU detection utilities\n",
    "from utils.gpu.detection import get_available_gpus, select_best_gpu\n",
    "from utils.gpu.optimization import optimize_cuda_memory_usage\n",
    "from utils.memory_utils import log_memory_usage, clear_memory\n",
    "\n",
    "# Detect available GPUs\n",
    "available_gpus = get_available_gpus()\n",
    "logger.info(f\"Available GPUs: {available_gpus}\")\n",
    "\n",
    "# Select best GPU if available\n",
    "if USE_GPU and available_gpus:\n",
    "    gpu_id = select_best_gpu()\n",
    "    logger.info(f\"Selected GPU {gpu_id} for primary processing\")\n",
    "    \n",
    "    # Configure environment for GPU usage\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    \n",
    "    # Optimize CUDA memory usage\n",
    "    optimize_cuda_memory_usage(reserve_memory_fraction=0.1)\n",
    "    \n",
    "    try:\n",
    "        # Try to import torch for GPU memory info\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            # Get GPU memory info\n",
    "            free_bytes = torch.cuda.memory_reserved(0) - torch.cuda.memory_allocated(0)\n",
    "            total_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "            logger.info(f\"GPU memory: {free_bytes/(1024**3):.2f} GB free / {total_bytes/(1024**3):.2f} GB total\")\n",
    "            logger.info(f\"CUDA version: {torch.version.cuda}\")\n",
    "            \n",
    "            # Run test to verify GPU acceleration\n",
    "            test_tensor = torch.ones((10, 10), device='cuda')\n",
    "            test_result = test_tensor + test_tensor\n",
    "            logger.info(\"PyTorch GPU test successful - tensor operations working\")\n",
    "        else:\n",
    "            logger.warning(\"PyTorch is installed but CUDA is not available\")\n",
    "    except ImportError:\n",
    "        logger.warning(\"PyTorch not available, skipping GPU memory check\")\n",
    "else:\n",
    "    logger.warning(\"No GPUs available or GPU usage disabled\")\n",
    "    USE_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Retrieval\n",
    "\n",
    "Now we'll download data from Numerai and Yiedl APIs. This includes training data, validation data, and live prediction targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip data download if SKIP_DOWNLOAD is True\n",
    "if SKIP_DOWNLOAD:\n",
    "    logger.info(\"Skipping data download (SKIP_DOWNLOAD=True)\")\n",
    "else:\n",
    "    # Import data retrieval module\n",
    "    from scripts.data.download_data import download_numerai_data, download_yiedl_data\n",
    "    \n",
    "    logger.info(\"Starting data download...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Download Numerai data\n",
    "    logger.info(\"Downloading Numerai data...\")\n",
    "    numerai_result = download_numerai_data(\n",
    "        include_historical=INCLUDE_HISTORICAL,\n",
    "        force=True  # Force download to ensure we have the latest data\n",
    "    )\n",
    "    \n",
    "    if numerai_result:\n",
    "        logger.info(\"Numerai data downloaded successfully\")\n",
    "    else:\n",
    "        logger.error(\"Failed to download Numerai data\")\n",
    "    \n",
    "    # Download Yiedl data if not skipped\n",
    "    if not SKIP_YIEDL:\n",
    "        logger.info(\"Downloading Yiedl data...\")\n",
    "        yiedl_result = download_yiedl_data(\n",
    "            include_historical=INCLUDE_HISTORICAL\n",
    "        )\n",
    "        \n",
    "        if yiedl_result:\n",
    "            logger.info(\"Yiedl data downloaded successfully\")\n",
    "        else:\n",
    "            logger.error(\"Failed to download Yiedl data\")\n",
    "    \n",
    "    download_time = time.time() - start_time\n",
    "    logger.info(f\"Data download completed in {download_time:.2f} seconds\")\n",
    "    \n",
    "    # Display available data files\n",
    "    numerai_files = [f for f in os.listdir(RAW_DATA_DIR) if f.startswith('numerai')]\n",
    "    logger.info(f\"Available Numerai files: {numerai_files}\")\n",
    "    \n",
    "    if not SKIP_YIEDL:\n",
    "        yiedl_files = [f for f in os.listdir(RAW_DATA_DIR) if f.startswith('yiedl')]\n",
    "        logger.info(f\"Available Yiedl files: {yiedl_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Processing\n",
    "\n",
    "Now we'll process the raw data to prepare it for feature generation and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data processing module\n",
    "from scripts.data.process_data import process_numerai_data, process_yiedl_data, merge_datasets\n",
    "\n",
    "logger.info(\"Starting data processing...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Determine raw data file paths\n",
    "numerai_train_file = os.path.join(RAW_DATA_DIR, \"numerai_train.parquet\")\n",
    "numerai_targets_file = os.path.join(RAW_DATA_DIR, \"numerai_targets.parquet\")\n",
    "numerai_live_file = os.path.join(RAW_DATA_DIR, \"numerai_live.parquet\")\n",
    "\n",
    "# Process Numerai data\n",
    "logger.info(\"Processing Numerai data...\")\n",
    "numerai_processed = process_numerai_data(\n",
    "    train_file=numerai_train_file,\n",
    "    targets_file=numerai_targets_file,\n",
    "    live_file=numerai_live_file,\n",
    "    output_dir=PROCESSED_DATA_DIR\n",
    ")\n",
    "\n",
    "if not SKIP_YIEDL:\n",
    "    # Determine Yiedl file paths\n",
    "    yiedl_latest_file = os.path.join(RAW_DATA_DIR, \"yiedl_latest.parquet\")\n",
    "    yiedl_historical_file = os.path.join(RAW_DATA_DIR, \"yiedl_historical.parquet\") if INCLUDE_HISTORICAL else None\n",
    "    \n",
    "    # Process Yiedl data\n",
    "    logger.info(\"Processing Yiedl data...\")\n",
    "    yiedl_processed = process_yiedl_data(\n",
    "        latest_file=yiedl_latest_file,\n",
    "        historical_file=yiedl_historical_file,\n",
    "        output_dir=PROCESSED_DATA_DIR\n",
    "    )\n",
    "    \n",
    "    # Merge Numerai and Yiedl data\n",
    "    logger.info(\"Merging Numerai and Yiedl data...\")\n",
    "    merged_data = merge_datasets(\n",
    "        numerai_data=numerai_processed['train'],\n",
    "        yiedl_data=yiedl_processed['processed'],\n",
    "        output_dir=PROCESSED_DATA_DIR\n",
    "    )\n",
    "else:\n",
    "    # If skipping Yiedl, just use Numerai data\n",
    "    logger.info(\"Skipping Yiedl data, using only Numerai data\")\n",
    "    merged_data = numerai_processed\n",
    "\n",
    "processing_time = time.time() - start_time\n",
    "logger.info(f\"Data processing completed in {processing_time:.2f} seconds\")\n",
    "\n",
    "# Display processed data files\n",
    "processed_files = os.listdir(PROCESSED_DATA_DIR)\n",
    "logger.info(f\"Available processed files: {processed_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Generation\n",
    "\n",
    "Now we'll generate features from the processed data using GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature generation module\n",
    "from scripts.features.gpu_accelerator import GPUFeatureAccelerator\n",
    "from scripts.run_fast_iterative_evolution import FeatureEvolver\n",
    "\n",
    "logger.info(\"Starting feature generation...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Determine input file for feature generation\n",
    "input_file = os.path.join(PROCESSED_DATA_DIR, \"crypto_train.parquet\")\n",
    "if not os.path.exists(input_file):\n",
    "    logger.warning(f\"{input_file} not found, looking for alternatives...\")\n",
    "    alternatives = [f for f in os.listdir(PROCESSED_DATA_DIR) if f.endswith('.parquet')]\n",
    "    if alternatives:\n",
    "        input_file = os.path.join(PROCESSED_DATA_DIR, alternatives[0])\n",
    "        logger.info(f\"Using alternative input file: {input_file}\")\n",
    "    else:\n",
    "        logger.error(\"No suitable input file found for feature generation\")\n",
    "\n",
    "# Load data\n",
    "logger.info(f\"Loading data from {input_file}...\")\n",
    "try:\n",
    "    # Try using polars first (faster)\n",
    "    import polars as pl\n",
    "    df = pl.read_parquet(input_file)\n",
    "    logger.info(f\"Loaded data with polars: {df.shape}\")\n",
    "except ImportError:\n",
    "    # Fall back to pandas if polars is not available\n",
    "    import pandas as pd\n",
    "    df = pd.read_parquet(input_file)\n",
    "    logger.info(f\"Loaded data with pandas: {df.shape}\")\n",
    "\n",
    "# Generate features using fast iterative evolution\n",
    "if EXECUTION_MODE == 'optimal':\n",
    "    logger.info(\"Using Fast Iterative Feature Evolution for optimal feature generation...\")\n",
    "    \n",
    "    # Initialize feature evolver\n",
    "    evolver = FeatureEvolver(\n",
    "        input_file=input_file,\n",
    "        output_dir=FEATURES_DIR,\n",
    "        max_iterations=MAX_ITERATIONS,\n",
    "        features_per_iteration=FEATURES_PER_ITERATION,\n",
    "        use_gpu=USE_GPU,\n",
    "        memory_limit_gb=GPU_MEMORY_LIMIT * 2  # Double GPU memory for system RAM\n",
    "    )\n",
    "    \n",
    "    # Run evolution\n",
    "    evolved_features = evolver.run()\n",
    "    \n",
    "    # Save final feature file path\n",
    "    feature_file = evolved_features.get('output_file') if evolved_features else None\n",
    "else:\n",
    "    # For quick mode, use simple GPU acceleration without evolution\n",
    "    logger.info(\"Using simple GPU acceleration for quick feature generation...\")\n",
    "    \n",
    "    # Initialize GPU accelerator\n",
    "    accelerator = GPUFeatureAccelerator(output_dir=FEATURES_DIR, force_gpu=USE_GPU)\n",
    "    \n",
    "    # Get numeric columns for feature generation\n",
    "    excluded_cols = ['target', 'Symbol', 'symbol', 'Prediction', 'prediction', \n",
    "                     'date', 'era', 'id', 'asset', '__index_level_0__']\n",
    "    \n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    else:  # polars DataFrame\n",
    "        numeric_cols = [col for col in df.columns if df[col].dtype in \n",
    "                        [pl.Float32, pl.Float64, pl.Int32, pl.Int64, pl.Int16, pl.Int8]]\n",
    "    \n",
    "    # Filter out non-feature columns\n",
    "    numeric_cols = [col for col in numeric_cols if col not in excluded_cols]\n",
    "    \n",
    "    # Limit number of columns for quick mode\n",
    "    if len(numeric_cols) > 20:\n",
    "        numeric_cols = numeric_cols[:20]\n",
    "    \n",
    "    logger.info(f\"Generating features for {len(numeric_cols)} numeric columns...\")\n",
    "    \n",
    "    # Generate features with simplified parameters for quick mode\n",
    "    result_df = accelerator.generate_all_features(\n",
    "        df,\n",
    "        group_col='symbol',\n",
    "        numeric_cols=numeric_cols,\n",
    "        rolling_windows=[7, 14],  # Simplified windows\n",
    "        lag_periods=[1, 3, 7],    # Simplified lags\n",
    "        ewm_spans=[5, 10],        # Simplified EWM spans\n",
    "        date_col='date' if 'date' in df.columns else None\n",
    "    )\n",
    "    \n",
    "    # Save features\n",
    "    feature_file = os.path.join(FEATURES_DIR, f\"quick_features_{datetime.now().strftime('%Y%m%d_%H%M')}.parquet\")\n",
    "    \n",
    "    if isinstance(result_df, pd.DataFrame):\n",
    "        result_df.to_parquet(feature_file)\n",
    "    else:  # polars DataFrame\n",
    "        result_df.write_parquet(feature_file)\n",
    "    \n",
    "    logger.info(f\"Features saved to {feature_file}\")\n",
    "\n",
    "feature_generation_time = time.time() - start_time\n",
    "logger.info(f\"Feature generation completed in {feature_generation_time:.2f} seconds\")\n",
    "\n",
    "# Clean up memory\n",
    "clear_memory()\n",
    "log_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Now we'll train multiple models using the generated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model training modules\n",
    "from scripts.models.lightgbm_model import LightGBMModel\n",
    "from scripts.models.xgboost_model import XGBoostModel\n",
    "from scripts.models.ensemble import ModelEnsemble\n",
    "\n",
    "logger.info(\"Starting model training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Load features data\n",
    "if feature_file and os.path.exists(feature_file):\n",
    "    logger.info(f\"Loading features from {feature_file}...\")\n",
    "    try:\n",
    "        # Try using polars first (faster)\n",
    "        import polars as pl\n",
    "        features_df = pl.read_parquet(feature_file)\n",
    "        # Convert to pandas for compatibility with models\n",
    "        features_df = features_df.to_pandas()\n",
    "    except ImportError:\n",
    "        # Fall back to pandas\n",
    "        features_df = pd.read_parquet(feature_file)\n",
    "    \n",
    "    logger.info(f\"Loaded features with shape: {features_df.shape}\")\n",
    "else:\n",
    "    # Look for any feature file if the specified one doesn't exist\n",
    "    feature_files = [f for f in os.listdir(FEATURES_DIR) if f.endswith('.parquet')]\n",
    "    if feature_files:\n",
    "        latest_feature_file = os.path.join(FEATURES_DIR, feature_files[-1])\n",
    "        logger.info(f\"Using latest feature file: {latest_feature_file}\")\n",
    "        features_df = pd.read_parquet(latest_feature_file)\n",
    "    else:\n",
    "        logger.error(\"No feature files found. Cannot train models.\")\n",
    "        raise FileNotFoundError(\"No feature files found for model training\")\n",
    "\n",
    "# Clean up features data\n",
    "logger.info(\"Cleaning features data...\")\n",
    "\n",
    "# Drop non-feature columns for training\n",
    "excluded_cols = ['target', 'Symbol', 'symbol', 'Prediction', 'prediction', \n",
    "                 'date', 'era', 'id', 'asset', '__index_level_0__']\n",
    "\n",
    "# Keep track of target column\n",
    "target_col = 'target'\n",
    "if target_col not in features_df.columns:\n",
    "    logger.error(f\"Target column '{target_col}' not found in features data\")\n",
    "    raise ValueError(f\"Target column '{target_col}' not found in features data\")\n",
    "\n",
    "# Drop rows with NaN in target\n",
    "features_df = features_df.dropna(subset=[target_col])\n",
    "logger.info(f\"Data shape after dropping NaN targets: {features_df.shape}\")\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "feature_cols = [col for col in features_df.columns \n",
    "                if col not in excluded_cols and col != target_col]\n",
    "X = features_df[feature_cols]\n",
    "y = features_df[target_col]\n",
    "\n",
    "# Fill NaN values in features\n",
    "X = X.fillna(0)\n",
    "\n",
    "logger.info(f\"Prepared {len(feature_cols)} features for training\")\n",
    "\n",
    "# Create a train/validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logger.info(f\"Training set: {X_train.shape}, Validation set: {X_val.shape}\")\n",
    "\n",
    "# Initialize models\n",
    "models = []\n",
    "model_performance = {}\n",
    "\n",
    "# Train LightGBM model\n",
    "try:\n",
    "    logger.info(\"Training LightGBM model...\")\n",
    "    lgb_model = LightGBMModel(\n",
    "        use_gpu=USE_GPU,\n",
    "        gpu_device_id=0,\n",
    "        name=\"lightgbm_model\"\n",
    "    )\n",
    "    \n",
    "    # Configure Azure Synapse LightGBM if enabled\n",
    "    if USE_AZURE_SYNAPSE:\n",
    "        lgb_model.params.update({\n",
    "            'synapse_mode': True\n",
    "        })\n",
    "    \n",
    "    # Train model\n",
    "    lgb_result = lgb_model.train(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        num_boost_round=500 if EXECUTION_MODE == 'quick' else 1000,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"LightGBM training completed: Best iteration: {lgb_result['best_iteration']}\")\n",
    "    \n",
    "    # Save model\n",
    "    lgb_model_path = lgb_model.save_model(MODELS_DIR)\n",
    "    logger.info(f\"LightGBM model saved to {lgb_model_path}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    lgb_preds = lgb_model.predict(X_val)\n",
    "    lgb_rmse = np.sqrt(mean_squared_error(y_val, lgb_preds))\n",
    "    logger.info(f\"LightGBM validation RMSE: {lgb_rmse:.6f}\")\n",
    "    \n",
    "    models.append(lgb_model)\n",
    "    model_performance['lightgbm'] = lgb_rmse\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error training LightGBM model: {e}\")\n",
    "\n",
    "# Train XGBoost model\n",
    "try:\n",
    "    logger.info(\"Training XGBoost model...\")\n",
    "    xgb_model = XGBoostModel(\n",
    "        use_gpu=USE_GPU,\n",
    "        gpu_id=0,\n",
    "        name=\"xgboost_model\"\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    xgb_result = xgb_model.train(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        num_boost_round=500 if EXECUTION_MODE == 'quick' else 1000,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"XGBoost training completed: Best iteration: {xgb_result['best_iteration']}\")\n",
    "    \n",
    "    # Save model\n",
    "    xgb_model_path = xgb_model.save_model(MODELS_DIR)\n",
    "    logger.info(f\"XGBoost model saved to {xgb_model_path}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    xgb_preds = xgb_model.predict(X_val)\n",
    "    xgb_rmse = np.sqrt(mean_squared_error(y_val, xgb_preds))\n",
    "    logger.info(f\"XGBoost validation RMSE: {xgb_rmse:.6f}\")\n",
    "    \n",
    "    models.append(xgb_model)\n",
    "    model_performance['xgboost'] = xgb_rmse\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error training XGBoost model: {e}\")\n",
    "\n",
    "# Create ensemble model\n",
    "if len(models) > 0:\n",
    "    logger.info(\"Creating ensemble model...\")\n",
    "    ensemble = ModelEnsemble(name=\"ensemble_model\", weights_strategy=\"performance\")\n",
    "    \n",
    "    # Add models to ensemble with performance metrics\n",
    "    for model, model_name in zip(models, model_performance.keys()):\n",
    "        ensemble.add_model(model, performance_metric=model_performance[model_name])\n",
    "    \n",
    "    # Evaluate ensemble on validation set\n",
    "    ensemble_preds = ensemble.predict(X_val)\n",
    "    ensemble_rmse = np.sqrt(mean_squared_error(y_val, ensemble_preds))\n",
    "    logger.info(f\"Ensemble validation RMSE: {ensemble_rmse:.6f}\")\n",
    "    \n",
    "    # Save ensemble metadata\n",
    "    ensemble_path = ensemble.save(MODELS_DIR)\n",
    "    logger.info(f\"Ensemble model metadata saved to {ensemble_path}\")\n",
    "    \n",
    "    model_performance['ensemble'] = ensemble_rmse\n",
    "else:\n",
    "    logger.warning(\"No models trained successfully, skipping ensemble creation\")\n",
    "\n",
    "# Display model performance summary\n",
    "logger.info(\"Model performance summary:\")\n",
    "for model_name, rmse in model_performance.items():\n",
    "    logger.info(f\"  {model_name}: RMSE = {rmse:.6f}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "logger.info(f\"Model training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Clean up memory\n",
    "clear_memory()\n",
    "log_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction Generation\n",
    "\n",
    "Now we'll generate predictions for the live universe using our trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prediction utilities\n",
    "from utils.model.predict import generate_predictions\n",
    "from scripts.python_utils.submission_utils import check_submission_format\n",
    "\n",
    "logger.info(\"Starting prediction generation...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Load live data for prediction\n",
    "live_file = os.path.join(PROCESSED_DATA_DIR, \"crypto_live.parquet\")\n",
    "if not os.path.exists(live_file):\n",
    "    logger.warning(f\"{live_file} not found, looking for alternatives...\")\n",
    "    alternatives = [f for f in os.listdir(PROCESSED_DATA_DIR) if 'live' in f and f.endswith('.parquet')]\n",
    "    if alternatives:\n",
    "        live_file = os.path.join(PROCESSED_DATA_DIR, alternatives[0])\n",
    "        logger.info(f\"Using alternative live file: {live_file}\")\n",
    "    else:\n",
    "        logger.error(\"No suitable live file found for prediction\")\n",
    "        raise FileNotFoundError(\"No live data file found for prediction\")\n",
    "\n",
    "logger.info(f\"Loading live data from {live_file}...\")\n",
    "try:\n",
    "    # Try using polars first (faster)\n",
    "    import polars as pl\n",
    "    live_df = pl.read_parquet(live_file)\n",
    "    # Convert to pandas for compatibility with models\n",
    "    live_df = live_df.to_pandas()\n",
    "except ImportError:\n",
    "    # Fall back to pandas\n",
    "    live_df = pd.read_parquet(live_file)\n",
    "\n",
    "logger.info(f\"Loaded live data with shape: {live_df.shape}\")\n",
    "\n",
    "# Ensure 'symbol' column is present for submission\n",
    "symbol_col = None\n",
    "for col_name in ['symbol', 'Symbol', 'asset']:\n",
    "    if col_name in live_df.columns:\n",
    "        symbol_col = col_name\n",
    "        break\n",
    "\n",
    "if symbol_col is None:\n",
    "    logger.error(\"No symbol column found in live data\")\n",
    "    raise ValueError(\"No symbol column found in live data\")\n",
    "\n",
    "# Generate features for live data (same feature set as training)\n",
    "logger.info(\"Generating features for live data...\")\n",
    "\n",
    "# If we have access to the same feature engineering pipeline\n",
    "if 'GPUFeatureAccelerator' in globals():\n",
    "    accelerator = GPUFeatureAccelerator(output_dir=FEATURES_DIR, force_gpu=USE_GPU)\n",
    "    \n",
    "    # Use the same feature generation parameters as training\n",
    "    # This is crucial for model predictions to work correctly\n",
    "    excluded_cols = ['target', 'Symbol', 'symbol', 'Prediction', 'prediction', \n",
    "                    'date', 'era', 'id', 'asset', '__index_level_0__']\n",
    "    \n",
    "    numeric_cols = live_df.select_dtypes(include=['number']).columns.tolist()\n",
    "    numeric_cols = [col for col in numeric_cols if col not in excluded_cols]\n",
    "    \n",
    "    # Limit number of columns to match training\n",
    "    if len(numeric_cols) > 20 and EXECUTION_MODE == 'quick':\n",
    "        numeric_cols = numeric_cols[:20]\n",
    "    \n",
    "    # Generate the same features as training\n",
    "    live_features_df = accelerator.generate_all_features(\n",
    "        live_df,\n",
    "        group_col=symbol_col,\n",
    "        numeric_cols=numeric_cols,\n",
    "        rolling_windows=[7, 14] if EXECUTION_MODE == 'quick' else [3, 7, 14, 28, 56],\n",
    "        lag_periods=[1, 3, 7] if EXECUTION_MODE == 'quick' else [1, 2, 3, 5, 7, 14, 28],\n",
    "        ewm_spans=[5, 10] if EXECUTION_MODE == 'quick' else [5, 10, 20, 40],\n",
    "        date_col='date' if 'date' in live_df.columns else None\n",
    "    )\n",
    "    \n",
    "    # Convert to pandas if needed\n",
    "    if not isinstance(live_features_df, pd.DataFrame):\n",
    "        live_features_df = live_features_df.to_pandas()\n",
    "else:\n",
    "    # If we don't have access to the feature engineering pipeline,\n",
    "    # we need to ensure the live data has the same features as the training data\n",
    "    logger.warning(\"Feature generation unavailable, using live data as-is\")\n",
    "    live_features_df = live_df\n",
    "\n",
    "logger.info(f\"Live features shape: {live_features_df.shape}\")\n",
    "\n",
    "# Filter live features to match training features\n",
    "if set(X.columns) - set(live_features_df.columns):\n",
    "    missing_cols = set(X.columns) - set(live_features_df.columns)\n",
    "    logger.warning(f\"Missing {len(missing_cols)} columns in live data\")\n",
    "    \n",
    "    # Add missing columns with zeros\n",
    "    for col in missing_cols:\n",
    "        live_features_df[col] = 0\n",
    "    \n",
    "    logger.info(f\"Added missing columns with zeros\")\n",
    "\n",
    "# Select only the features used in training\n",
    "live_X = live_features_df[X.columns]\n",
    "live_X = live_X.fillna(0)\n",
    "\n",
    "logger.info(f\"Prepared live features with shape: {live_X.shape}\")\n",
    "\n",
    "# Generate predictions using each model\n",
    "predictions = {}\n",
    "\n",
    "for model_name in model_performance.keys():\n",
    "    if model_name == 'ensemble' and 'ensemble' in locals():\n",
    "        logger.info(f\"Generating predictions with ensemble model...\")\n",
    "        pred = ensemble.predict(live_X)\n",
    "        predictions['ensemble'] = pred\n",
    "    elif model_name == 'lightgbm' and 'lgb_model' in locals():\n",
    "        logger.info(f\"Generating predictions with LightGBM model...\")\n",
    "        pred = lgb_model.predict(live_X)\n",
    "        predictions['lightgbm'] = pred\n",
    "    elif model_name == 'xgboost' and 'xgb_model' in locals():\n",
    "        logger.info(f\"Generating predictions with XGBoost model...\")\n",
    "        pred = xgb_model.predict(live_X)\n",
    "        predictions['xgboost'] = pred\n",
    "    else:\n",
    "        logger.warning(f\"Model {model_name} not available for prediction\")\n",
    "\n",
    "# Use ensemble predictions if available, otherwise use best single model\n",
    "if 'ensemble' in predictions:\n",
    "    final_predictions = predictions['ensemble']\n",
    "    model_used = 'ensemble'\n",
    "elif predictions:\n",
    "    # Find best model based on validation performance\n",
    "    best_model = min(model_performance.items(), key=lambda x: x[1])[0]\n",
    "    if best_model in predictions:\n",
    "        final_predictions = predictions[best_model]\n",
    "        model_used = best_model\n",
    "    else:\n",
    "        # Use first available model\n",
    "        model_used = list(predictions.keys())[0]\n",
    "        final_predictions = predictions[model_used]\n",
    "else:\n",
    "    logger.error(\"No predictions generated\")\n",
    "    raise RuntimeError(\"No predictions generated\")\n",
    "\n",
    "logger.info(f\"Using predictions from {model_used} model\")\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'symbol': live_features_df[symbol_col],\n",
    "    'prediction': final_predictions\n",
    "})\n",
    "\n",
    "# Ensure lowercase 'symbol' column\n",
    "if 'symbol' not in submission_df.columns and symbol_col in submission_df.columns:\n",
    "    submission_df = submission_df.rename(columns={symbol_col: 'symbol'})\n",
    "\n",
    "# Ensure values are in [0, 1] range\n",
    "submission_df['prediction'] = submission_df['prediction'].clip(0, 1)\n",
    "\n",
    "# Save submission file\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "submission_file = os.path.join(SUBMISSION_DIR, f\"submission_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\")\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "\n",
    "logger.info(f\"Saved submission with {len(submission_df)} predictions to {submission_file}\")\n",
    "\n",
    "# Check submission format\n",
    "if check_submission_format(submission_file):\n",
    "    logger.info(\"Submission format is valid\")\n",
    "else:\n",
    "    logger.warning(\"Submission format is invalid, please check the file\")\n",
    "\n",
    "prediction_time = time.time() - start_time\n",
    "logger.info(f\"Prediction generation completed in {prediction_time:.2f} seconds\")\n",
    "\n",
    "# Preview submission\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Summary\n",
    "\n",
    "Now we'll summarize the performance of the pipeline and the generated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total execution time\n",
    "total_time = 0\n",
    "if 'download_time' in locals():\n",
    "    total_time += download_time\n",
    "if 'processing_time' in locals():\n",
    "    total_time += processing_time\n",
    "if 'feature_generation_time' in locals():\n",
    "    total_time += feature_generation_time\n",
    "if 'training_time' in locals():\n",
    "    total_time += training_time\n",
    "if 'prediction_time' in locals():\n",
    "    total_time += prediction_time\n",
    "\n",
    "# Format as hours, minutes, seconds\n",
    "hours = int(total_time // 3600)\n",
    "minutes = int((total_time % 3600) // 60)\n",
    "seconds = int(total_time % 60)\n",
    "\n",
    "logger.info(f\"Total pipeline execution time: {hours}h {minutes}m {seconds}s\")\n",
    "\n",
    "# Display final model performance summary\n",
    "if 'model_performance' in locals() and model_performance:\n",
    "    logger.info(\"\\nModel Performance Summary:\")\n",
    "    for model_name, rmse in sorted(model_performance.items(), key=lambda x: x[1]):\n",
    "        logger.info(f\"  {model_name}: RMSE = {rmse:.6f}\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = min(model_performance.items(), key=lambda x: x[1])[0]\n",
    "    best_rmse = model_performance[best_model]\n",
    "    logger.info(f\"\\nBest model: {best_model} with RMSE = {best_rmse:.6f}\")\n",
    "\n",
    "# Display submission information\n",
    "if 'submission_file' in locals() and os.path.exists(submission_file):\n",
    "    submission_size = os.path.getsize(submission_file) / 1024  # KB\n",
    "    logger.info(f\"\\nSubmission file: {submission_file}\")\n",
    "    logger.info(f\"Submission size: {submission_size:.2f} KB\")\n",
    "    logger.info(f\"Number of predictions: {len(submission_df)}\")\n",
    "    \n",
    "    # Display submission statistics\n",
    "    logger.info(f\"Prediction range: [{submission_df['prediction'].min():.4f}, {submission_df['prediction'].max():.4f}]\")\n",
    "    logger.info(f\"Prediction mean: {submission_df['prediction'].mean():.4f}\")\n",
    "    logger.info(f\"Prediction std: {submission_df['prediction'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Submitting to Numerai\n",
    "\n",
    "Finally, we'll show how to submit the predictions to the Numerai competition. You need to set your Numerai API credentials for this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to submit to Numerai\n",
    "SUBMIT_TO_NUMERAI = False\n",
    "\n",
    "if SUBMIT_TO_NUMERAI:\n",
    "    try:\n",
    "        # Try to import numerapi\n",
    "        import numerapi\n",
    "        \n",
    "        # Set your Numerai API credentials\n",
    "        # You can get these from https://numer.ai/account\n",
    "        public_id = os.environ.get('NUMERAI_PUBLIC_ID', None)\n",
    "        secret_key = os.environ.get('NUMERAI_SECRET_KEY', None)\n",
    "        \n",
    "        if not public_id or not secret_key:\n",
    "            logger.warning(\"Numerai API credentials not set. Set NUMERAI_PUBLIC_ID and NUMERAI_SECRET_KEY environment variables.\")\n",
    "        else:\n",
    "            # Initialize Numerai API client\n",
    "            napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n",
    "            \n",
    "            # Check if we have a valid submission file\n",
    "            if 'submission_file' in locals() and os.path.exists(submission_file):\n",
    "                # Submit predictions\n",
    "                logger.info(f\"Submitting predictions to Numerai...\")\n",
    "                submission_id = napi.upload_predictions(submission_file, tournament=TOURNAMENT_NAME)\n",
    "                logger.info(f\"Submission successful! Submission ID: {submission_id}\")\n",
    "            else:\n",
    "                logger.error(\"No valid submission file found\")\n",
    "    except ImportError:\n",
    "        logger.error(\"numerapi package not installed. Install it with: pip install numerapi\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error submitting to Numerai: {e}\")\n",
    "else:\n",
    "    logger.info(\"Skipping submission to Numerai (SUBMIT_TO_NUMERAI=False)\")\n",
    "    logger.info(\"To submit manually, upload the submission file at: https://numer.ai/tournament\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "We've successfully run the complete Numerai Crypto prediction pipeline. Here's a summary of what we've accomplished:\n",
    "\n",
    "1. Downloaded and processed data from Numerai and Yiedl (if enabled)\n",
    "2. Generated features using GPU-accelerated algorithms\n",
    "3. Trained multiple models (LightGBM, XGBoost) and created an ensemble\n",
    "4. Generated predictions for the live universe\n",
    "5. Created a valid submission file ready for Numerai\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Experiment with different feature generation parameters\n",
    "- Try different model architectures and hyperparameters\n",
    "- Run the pipeline in 'optimal' mode for best performance\n",
    "- Submit your predictions to the Numerai Crypto tournament\n",
    "\n",
    "### Performance Strategies\n",
    "\n",
    "The repository implements multiple prediction strategies:\n",
    "\n",
    "1. **Mean Reversion Strategy**: Assumes prices will revert to historical average (RMSE: 0.0893)\n",
    "2. **Momentum Strategy**: Assumes price trends will continue (RMSE: 0.1117)\n",
    "3. **Trend Following Strategy**: Follows established price trends (RMSE: 0.1079)\n",
    "4. **Ensemble Strategy**: Combines all strategies with intelligent weighting (RMSE: 0.1050)\n",
    "\n",
    "The optimal pipeline combines all these strategies for the best performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}